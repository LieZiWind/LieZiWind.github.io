---
layout: post
title:  "Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-contradictory Instructions"
date:   2024-02-27 20:32:34 +00:00
image: /images/conflictllm.png
categories: research
authors: "Jin Gao, Lei Gan*, <strong>Yuankai Li*</strong>, Yixin Ye, Dequan Wang"
venue: "ECCV 2024"
paper: https://selfcontradiction.github.io
huggingface: https://huggingface.co/datasets/sci-benchmark/self-contradictory
code: https://github.com/shiyegao/Self-Contradictory-Instructions-SCI
# subtitle: "Adding Natural User Interfaces to Software"

---

We introduce the idea of self-contradictory instructions in Large Multimodal Models(LMMs), emphasized its potential harm, and sought to benchmark and address this problem.
